import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist         # библиотека базы выборок Mnist
from tensorflow import keras
import tensorflow as tf
import random
from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv1D, MaxPooling1D
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# ==========================================================================
# !                Это  из примеров по изображениям                        !
# !                Запускать только для осознания !!!                      !
# !                В окончательной версии запускать не нужно !!!           !
# ==========================================================================
# Загружаем картинки с рукописными ифрами, чтобы понять, какова размерность
# получающихся тензоров x_train, y_train
(x_train, y_train), (x_test, y_test) = mnist.load_data()
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# ==========================================================================
# !                Это  из примеров по изображениям                        !
# !                Запускать только для осознания !!!                      !
# !                В окончательной версии запускать не нужно !!!           !
# ==========================================================================
print("Размер обучающих данных x_train: ", tf.shape(x_train).numpy())
print("Размер обучающих данных y_train: ", tf.shape(y_train).numpy())
#print(x_train)
# В результате видим, что x_train имеет размер [60000    28    28]
# а y_train [60000]
# Значит в нашем случае 60000 обозначим V - Объём обучающей выборки
# а вместо 28 28 у нас будет одно число - количестово отсчётов на 
# интервале наблюдения. Обозначим его N. Когда длительность сигнала 
# известна, то интервал наблюдениия будет совпадать с длительностью.
# А если длительность неизвестна, то количество отсчётов на интервале 
# наблюдения должно быть больше, чем количество отсчётов на длительности
# Tau >= N
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# ==========================================================================
# !                Это  из примеров по изображениям                        !
# !                Запускать только для осознания !!!                      !
# !                В окончательной версии запускать не нужно !!!           !
# ==========================================================================
print("Размер обучающих данных x_test: ", tf.shape(x_test).numpy())
print("Размер обучающих данных y_test: ", tf.shape(y_test).numpy())
#print(x_test)
# Для тестовой выбоки размер 10000 обозначим M
# На основе этой выборки вычисляются вероятности ошибок,
# поэтому M нужно делать немаленьким - для достоверности.
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
V = 1000  # Количество формируемых реализаций для обучения как  60000
M = 1000  # Количество формируемых реализаций для верификации
N = 1024 # Количество отсчётов на интервале наблюдения
Tau = 300 # Длительность сигнала в отсчётах
MinL = 0 # Минимальное значение момента появления
MaxL = N-Tau # Максимальное значение момента появления
p0 = 0.5 # Вероятность отсутствия сигнала
p1 = 1 - p0 # Вероятность наличия сигнала
L0 = 256
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Формируем шумовые слагаемые для обучающей выборки

t = np.array([i for i in range(N)]) # отсчёты времени в формате тензора

#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
nt = tf.random.normal((V,N)) # отсчёты ГБШ (статнезависимые случайные 
# с нулевым матожиданием и единичной дисперсией)

print(nt)
plt.plot(t,nt[0].numpy())
print("Размер отсчётов шума", tf.shape(nt).numpy())
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Описываем форму сигнала в виде функции. В качестве примера взяли 
# прямоугольный импульс. Длительность его можно изменять. 
# Можно также менять. время прихода - параметр L0 - это передний фронт 
# или момент появления. Чтобы сигнал расширить на весь интервал наблюдения
# нужно поставить L0=0, Tau=N

def signal(i,L0):
    if ((i>=L0)and(i<=L0+Tau)):
        return 1
    else: 
        return 0
  
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Заполняем массив отсчётов сигнала, пока без амплитуды.
# Чтобы сделать нужное отношение сигнал/шум (ОСШ), 
# нужно будет весь этот массив отсчётов сигнала умножить на 
# амплитуду.

s = np.array([signal(tt,L0) for tt in t])
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Строим сигнал на картинке
plt.plot(t,s)
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Будем реализовывать два способа обучения.
# 1) ОСШ заранее известно, тогда учим для фиксированного ОСШ, потом для 
# другого иполучаем вероятности ошибок для каждого ОСШ
z = 5

# 2) ОСШ неизвестно. Будем учить для всех случайно выбранных ОСШ.
#z = random.random()*20;


#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Формируем реализации для обучения
# Поскольку в обучающей выборке должны присутствовать реализации 
# с сигналом и без сигнала, его присутствие будем разыгрывать 
# с помощью случайной величины 
# if np.random.uniform()>p0 то сигнал есть
# Заодно эта разыгранная величина будет играть роль целевого значения

templist=[]
y_train = []
for m in range(V):
    # разыгрываем присутствие
    gamma0 = int(np.random.uniform()>p0)
    # формируем реализацию
    x = gamma0*s*z+nt[m]
    templist.append(x)
    y_train.append(gamma0)
x_train = templist

#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Проверяем размерность полученного обучающего набора
print("Размер обучающих данных x_train: ", tf.shape(x_train).numpy())
print("Размер обучающих данных y_train: ", tf.shape(y_train).numpy())
print(y_train)
#plt.plot(t,x_train[3])

#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Формируем аналогично реализации для тестирования
nt_test = tf.random.normal((M,N)) # отсчёты ГБШ (статнезависимые случайные 
# с нулевым матожиданием и единичной дисперсией)
templist_test=[]
y_test = []
for m in range(M):
    # разыгрываем присутствие
    gamma0 = int(np.random.uniform()>p0)
    # формируем реализацию
    x = gamma0*s*z+nt_test[m]
    templist_test.append(x)
    y_test.append(gamma0)
x_test = templist_test

#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Проверяем размерность полученного обучающего набора
print("Размер обучающих данных x_train: ", tf.shape(x_test).numpy())
print("Размер обучающих данных y_train: ", tf.shape(y_test).numpy())
#print(y_test)
#plt.plot(t,x_test[3])
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Начинаем формировать модель
# Сначала преобразуем обучающие данные под модель keras

# Целевые значения - по категориям.
# Это значит, что на выходе будет не один нейрон, который отвечает на 
# вопро был сигнал или нет, а два нейрона, работающих в противофазе
# Когда принимается решение о наличии сигнала, единиц появляется 
# на выходе одного из них (на выходе другого 0). 
# В случае отсутствии сигнала выходы нейронов меняются местами
y_train_cat = keras.utils.to_categorical(y_train, 2)
y_test_cat = keras.utils.to_categorical(y_test, 2)
print(y_test_cat)

#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Добавляем к входным данным ещё одну ось с номером 2
# Трудно объяснить внятно, зачем это нужно.
# Свёрточные слои преобразуют входные данные в карты признаков
# Сами входные данные тоже могут быть представлены картами признаков,
# например слои R,G,B при анализе изображения являются картами признаков.
# Наглядно можно представлять, как будто приксел является вектором из 
# трёх цветовых компонент. 
# Если изображение в оттенках серого, то оно является одной 
# картой признаков - пиксел является скаляром
# Аналогично у сигналов. Отсчёт сигнала у нас является скаляром. Поэтому 
# добавляем одну размерность - признак того, что имеет входные данные 
# в виде одной карты признаков. Как-то так.
x_train = np.expand_dims(x_train, axis=2)
x_test = np.expand_dims(x_test, axis=2)
print( x_train.shape )
# После выполнения этого фрагмента размерность тензора входных данных x_train
# равна (V,N,1), например (10,1024,1).


#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Формируем модель
model = keras.Sequential([
    Conv1D(32, 8, strides=1, padding='same', activation='relu', input_shape=(1024, 1)),
    MaxPooling1D(2, strides=2),
    Conv1D(64, 8, padding='same', activation='relu'),
    MaxPooling1D(2, strides=2),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(2,  activation='softmax')
])
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
print(model.summary())      # вывод структуры НС в консоль
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Настраиваем способ обучения
model.compile(optimizer='adam',
             loss='categorical_crossentropy',
             metrics=['accuracy'])
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Обучаем
his = model.fit(x_train, y_train_cat, batch_size=2, epochs=5, validation_split=0.2)
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
# Верифицируем
model.evaluate(x_test, y_test_cat)

#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%